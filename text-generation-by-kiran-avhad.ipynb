{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nimport string\n\nimport pandas as pd\nimport numpy as np\nimport requests\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\ndata=data.text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data[253:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=\" \".join(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(doc):\n    tokens=doc.split()\n    table=str.maketrans(\"\",\"\",string.punctuation)\n    tokens= [w.translate(table) for w in tokens]\n    tokens=[word for word in tokens if word.isalpha()]\n    tokens= [word.lower() for word in tokens]\n    return tokens\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens=clean_text(data)\nprint(tokens[:50])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unique words in data\nlen(set(tokens))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length=50+1\nlines=[]\nfor i in range(length,len(tokens)):\n    seq=tokens[i-length:i]\n    line=\" \".join(seq)\n    lines.append(line)\n    if i >200000:\n        break\nprint(len(lines))\n               ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding\nfrom  tensorflow.keras.preprocessing.sequence import pad_sequences\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toks=Tokenizer()\ntoks.fit_on_texts(lines)\nsequence=toks.texts_to_sequences(lines)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence=np.array(sequence)\nlen(sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_length=len(sequence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y=sequence[:,:-1],sequence[:,-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size=len(toks.word_index)+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=to_categorical(y,num_classes=vocab_size)\ny.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(vocab_size,50,input_length=seq_length))\nmodel.add(LSTM(100,return_sequences=True))\nmodel.add(LSTM(100))\nmodel.add(Dense(vocab_size,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',metrics='accuracy',loss='categorical_crossentropy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x,y,batch_size=64,epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}